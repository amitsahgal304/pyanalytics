import mlxtend
import pandas as pd
import numpy as np
import mlxtend as ml
from mlxtend.frequent_patterns import apriori, association_rules
import matplotlib.pyplot as plt

df=pd.read_csv('/Users/amitsahgal/Desktop/retail_data.csv',sep=',')
df.head()
#def custom():
encoded_vals = []
for index, row in df.iterrows():
    labels = {}
    uncommons = list(set(items) - set(row))
    commons = list(set(items).intersection(row))
    
    for uc in uncommons:
        labels[uc] = 0
    for com in commons:
        labels[com] = 1
        encoded_vals.append(labels)
encoded_vals[0]

#def custom():
encoded_vals = []
for index, row in df.iterrows():
    labels = {}
    uncommons = list(set(items) - set(row))
    commons = list(set(items).intersection(row))
    
    for uc in uncommons:
        labels[uc] = 0
    for com in commons:
        labels[com] = 1
        encoded_vals.append(labels)
encoded_vals

def custom():
encoded_vals = []
for index, row in df.iterrows():
    labels = {}
    uncommons = list(set(items) - set(row))
    commons = list(set(items).intersection(row))
    
    for uc in uncommons:
        labels[uc] = 0
    for com in commons:
        labels[com] = 1
        print (labels)
        encoded_vals.append(labels)
        
        encoded_vals = []
for index, row in df.iterrows():
    labels = {}
    uncommons = list(set(items) - set(row))
    commons = list(set(items).intersection(row))
    
    for uc in uncommons:
        labels[uc] = 0
    for com in commons:
        labels[com] = 1
        encoded_vals.append(labels)
encoded_vals[0]
ohe_df-pd.DataFrame(encoded_vals)
ohe_df.head()

encoded_vals = []
for index, row in df.iterrows():
    labels = {}
    uncommons = list(set(items) - set(row))
    commons = list(set(items).intersection(row))
    
    for uc in uncommons:
        labels[uc] = 0
    for com in commons:
        labels[com] = 1
        encoded_vals.append(labels)
encoded_vals[0]
ohe_df-pd.DataFrame(encoded_vals)
ohe_df.head()
freq_items = apriori(ohe_df, min_support=0.2, use_colnames=True)
freq_items.head(6)
rules=association_rules(freq_items, metric='confidence', min_threshold=0.6)
rules.head(7)

#lift vs Confidence
fit=np.polyfit(rules['lift'], rules['confidence'],1)
fit_fn=np.poly1d(fit)
plt.xlabel('lift')
plt.ylabel('confidence')
plt.title('lift vs Confidence')
plt.plot(rules['lift'],rules['confidence'],'yo',rules['lift'],fit_fn(rules['lift']))

#Support vs Confidence
plt.scatter(rules['support'],rules['confidence'],alpha=0.5)
plt.xlabel('support')
plt.ylabel('confidence')
plt.title('Support vs Confidence')
plt.show()

#Lift vs Support
plt.scatter(rules['support'],rules['lift'],alpha=0.5)
plt.xlabel('support')
plt.ylabel('lift')
plt.title('Support vs lift')
plt.show()

#Lift vs Support(Use the line diagram)
plt.scatter(rules['confidence'],rules['lift'],alpha=0.5)
plt.xlabel('confidence')
plt.ylabel('lift')
plt.title('confidence vs lift')
plt.show()
